/* HMT project Mandatory Ongoing Maintenance. 
   Summer 2014 version.
*/
buildscript {
    repositories {
        mavenCentral()
	maven {
	  url "http://beta.hpcc.uh.edu/nexus/content/groups/public"
	}
    }
    dependencies {
      classpath group: 'org.homermultitext', name : 'citemgr' , version: '0.4.9'
      classpath group: 'org.homermultitext', name : 'hmt-utils' , version: '0.2.5'

      classpath group: 'edu.harvard.chs', name : 'cite' , version: '0.14.2'
      classpath group: 'edu.holycross.shot', name: 'hocuspocus', version : '0.7.27'

      classpath group: 'edu.harvard.chs', name : 'greekutils' , version: '0.8.5'

      classpath group : 'edu.unc.epidoc', name: 'transcoder', version : '1.2-SNAPSHOT'

      classpath group: 'net.sf.opencsv', name: 'opencsv', version: '2.3'


    }
}

import org.homermultitext.utils.HmtTokenizer

import edu.harvard.chs.cite.CiteUrn
import edu.harvard.chs.cite.CtsUrn

import edu.holycross.shot.hocuspocus.Corpus

import org.homermultitext.citemanager.DseManager

import edu.harvard.chs.f1k.GreekNode

import edu.unc.epidoc.transcoder.TransCoder

import au.com.bytecode.opencsv.CSVReader
import groovy.xml.StreamingMarkupBuilder

import org.apache.tools.ant.filters.*

apply plugin: "base"
apply plugin:  "groovy"
apply plugin:  "maven"


apply from: "versions.gradle"


if (hasProperty('conf')) {
    System.err.println "Using configuration data from ${conf}"
    File confFile = new File(conf)
    if (! confFile.exists()) {
        throw new Exception("No configuration file ${conf} found.")
    }
    apply from: conf

} else {
    File confFile = new File("conf.gradle")
    if (! confFile.exists()) {
        throw new Exception("No configuration file ${conf} found.")
    }
    System.err.println "Using conf.gradle for configuration"
    apply from: "conf.gradle"
    
}



if (hasProperty('repoconf')) {
    System.err.println "Using repository locations data from ${repoconf}"
    File confFile = new File(repoconf)
    if (! confFile.exists()) {
        throw new Exception("No file ${repoconf} found.")
    }
    apply from: repoconf

} else {
    File confFile = new File("repos.gradle")
    if (! confFile.exists()) {
        throw new Exception("No configuration file ${confFile} found.")
    }
    System.err.println "Using repos.gradle for finding repositories."
    apply from: "repos.gradle"
}



group = "org.homermultitext"
version = '0.6.0'


repositories {
    mavenCentral()
    maven {
        url "http://beta.hpcc.uh.edu/nexus/content/groups/public"
    }
}

dependencies {
  compile group: 'org.codehaus.groovy', name: 'groovy-all', version: groovyVersion
  compile group: 'org.homermultitext', name : 'citemgr' , version: '0.4.5'

  compile group: 'edu.harvard.chs', name : 'cite' , version: citeversion

    testCompile group: 'junit', name: 'junit', version: '4.8.2'

}


task palView() {
  description = "Creates HTML page displaying paleographic inventory data."
}

palView.doLast {
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File outputDir = new File(buildDir, "paleography")
  if (! outputDir.exists()) {
    outputDir.mkdir()
  }
  File outputFile = new File(outputDir, "viewer.html")


  String urnBase = "http://beta.hpcc.uh.edu/tomcat/hmt-digital/images?request=GetBinaryImage&w=9000&urn="

  File palFile = new File(paleo)
  CSVReader reader = new CSVReader(new FileReader(palFile))

  StreamingMarkupBuilder xml = new StreamingMarkupBuilder()
  xml.encoding = "UTF-8"

  def doc = xml.bind {
    mkp.xmlDeclaration()
    html {
      head () {
      }
      body{

	table {
	  tr {
	    th ("Reading")
	    th ("Image")
	  }
	  reader.readAll().each { ln ->
	    if (ln.size() >= 3) {
	      tr {
		CtsUrn urn
		String urnVal
		try {
		  urn = new CtsUrn(ln[1])
		  urnVal = urn.getSubref1()
		  td (urnVal)
		  td {
		    img(src : "${urnBase}${ln[2]}")
		  }

		} catch (Exception e) {
		  System.err.println "Bad CTS URN: " + ln[1]
		}
	      }
	    }
	  }
	}
      }
    }
  }
  outputFile.setText(doc.toString(), "UTF-8")
  System.err.println "Paleography observations in ${outputDir}/viewer.html"
} /*end palView task */


task setUpVisInv(type: Copy) {
  description="Copy template files for visual inventory to build area."
  from "visualinventory"
  into "${buildDir}/visualinventory"
}


task indexScholia() {
  description = "Reads inventory of scholia, and creates separate indices for surfaces and images"
}


indexScholia.doLast {
  if (!buildDir.exists()) {
    buildDir.mkdir()
  }
  File scholiaToTbs = new File(buildDir, "scholiaToTbs.csv")
  File scholiaToImg = new File(buildDir,"scholiaToImage.csv")

  scholiaInventories.split(/,/).each { inv ->

    if (inv) {
      File invFile = new File(inv)
      if (invFile) {
	CSVReader reader = new CSVReader(new FileReader(invFile))
	reader.readAll().each { ln ->
	  if (ln.size() == 3) {
	    scholiaToTbs.append(ln[0] + ',"' + ln[2] + '"\n')
	    scholiaToImg.append(ln[0] + ',"' + ln[1] + '"\n')
	  }
	}
      }
    }
  }
}


task dse(dependsOn : [setUpVisInv, indexScholia]) {
  description = "Does citemgr's DSE validation,  and creates an XML visual inventory for the specified folio."
}

dse.doLast {
  DseManager dse = new DseManager()

  folioToImage.split(/,/).each { idx ->
    if (dse.tbsImageIndexFiles) {
      dse.tbsImageIndexFiles.add(new File(idx))
    } else {
      dse.tbsImageIndexFiles = [new File(idx)]
    }
  }

  textToImage.split(/,/).each { idx ->
    if (dse.textImageIndexFiles) {
      dse.textImageIndexFiles.add(new File(idx))
    } else {
      dse.textImageIndexFiles = [new File(idx)]
    }
  }
  dse.textImageIndexFiles.add(new File(buildDir, "scholiaToImage.csv"))

  //System.err.printn ""

  textToFolio.split(/,/).each { idx ->
    if (dse.textTbsIndexFiles) {
      dse.textTbsIndexFiles.add(new File(idx))
    } else {
      dse.textTbsIndexFiles = [new File(idx)]
    }
  }
  dse.textTbsIndexFiles.add(new File (buildDir, "scholiaToTbs.csv"))

  println "textTbs idx: " + dse.textTbsIndexFiles

  CiteUrn  img = dse.imageForTbs(folio)

  System.err.println "Default image: " + img

  if (!img) {
    System.err.println "No default image for " + folio
  }
  def iMaps 
  try {
    iMaps = dse.imageMapsByText(img)
  } catch (Exception e)  {
    System.err.println "Unable to get image maps for ${img}."
  }

  CiteUrn urn = new CiteUrn(folio)
  String xml =  dse.getVisualInventoryXml(urn)

  String fName = "${buildDir}/visualinventory/inventory.xml"
  File visinv = new File(fName)
  visinv.setText(xml,"UTF-8")

  dse.verifyTbs(folio)

}


task tabulate(dependsOn: dse) {
  description = "Writes tabulated form of all inventoried texts in ${buildDir}/tabulated."
}


tabulate.doLast {
  File tiFile = new File(textInventory)
  File archiveDir = new File(textArchive)

  File tabDir = new File(buildDir,"tabulated")
  if (! buildDir.exists()) { 
    buildDir.mkdir()
  }
  if (! tabDir.exists()) {
    tabDir.mkdir()
  }

  Corpus c = new Corpus(tiFile, archiveDir)
  c.tabulateRepository(tabDir)
}

task tabsForSurface(dependsOn: tabulate) {
  description="Selects tabulated text data for requested text-bearing surface."
}

tabsForSurface.doLast {
  // input and output files:
  File tabsDir = new File(buildDir, "tabulated")

  // Get a hocuspocus corpus for text repository:
  File archiveDir = new File(textArchive)
  File tiFile = new File(textInventory)
  Corpus corpus = new Corpus(tiFile, archiveDir)

  // configure a DseManager:
  DseManager dse = new DseManager()

  folioToImage.split(/,/).each { idx ->
    if (dse.tbsImageIndexFiles) {
      dse.tbsImageIndexFiles.add(new File(idx))
    } else {
      dse.tbsImageIndexFiles = [new File(idx)]
    }
  }

  textToImage.split(/,/).each { idx ->
    if (dse.textImageIndexFiles) {
      dse.textImageIndexFiles.add(new File(idx))
    } else {
      dse.textImageIndexFiles = [new File(idx)]
    }
  }
  dse.textImageIndexFiles.add(new File(buildDir, "scholiaToImage.csv"))

  textToFolio.split(/,/).each { idx ->
    if (dse.textTbsIndexFiles) {
      dse.textTbsIndexFiles.add(new File(idx))
    } else {
      dse.textTbsIndexFiles = [new File(idx)]
    }
  }
  dse.textTbsIndexFiles.add(new File (buildDir, "scholiaToTbs.csv"))


  // get relevant tabular data, and tokenize it:
  ArrayList tabData = dse.tabDataForSurface(folio, corpus, tabsDir)
  


  File outputDir = new File(buildDir, "surfaceTabs")
  if (! outputDir.exists()) {
    outputDir.mkdir()
  }

  File tabDataFile = new File(outputDir, "tab.txt")
  tabData.each {
    tabDataFile.append(it + "\n", "UTF-8")
  }

}

task tokenize(dependsOn: tabsForSurface) {
  description = "Creates HMT classified tokenization of texts for given page"
  
}

tokenize.doLast {
  // input and output files:
  File surfTabsDir = new File(buildDir, "surfaceTabs")
  File outputDir = new File(buildDir, "tokens")
  if (! outputDir.exists()) {
    outputDir.mkdir()
  }
  File tokensFile = new File(outputDir, "tokens.txt")

  String fldSeparator = "#"
  HmtTokenizer hmtTokens = new HmtTokenizer(surfTabsDir, tokensFile, fldSeparator)
  hmtTokens.tokenizeTabs()
}


task persNames(dependsOn: [tokenize]) {
  description  = "Check that personal name identifiers are valid."
}
persNames.doLast {
  File summaries = new File(buildDir,"summaries.txt")
  File verificationDir = new File(buildDir, "verification")

  File tokens = new File("${buildDir}/tokens/tokens.txt")
  if (tokens.exists()) {
    def persNames = tokens.readLines().findAll { l -> l ==~ /urn:cite:hmt:pers.+/}
    def occurrenceMap = [:]
    persNames.each { 
      def cols = it.split(/\t/)
      def pname = cols[0]
      def psg = cols[1]
      if (occurrenceMap[pname]) {
	def psgs = occurrenceMap[pname]
	psgs.add(psg)
	occurrenceMap[pname] =  psgs
      } else {
	occurrenceMap[pname] = [psg]
      }
    }

    def personsList = []
    File personsFile = new File (persnames)
    personsFile.eachLine {
      def cols = it.split(/,/)
      personsList.add(cols[0])
    }
    println "Check " + persNames.size() + " personal name occurrences  against " + personsList.size() + " authority list entries."
    
    Integer good = 0
    Integer bad = 0
    def scoreMap = [:]
    occurrenceMap.keySet().each { k ->
      if (personsList.contains(k)) {
	good++
	  
      } else {
	bad++
      }
    }
    //println "Score: ${good} / ${bad} / total: ${occurrenceMap.keySet().size()}"
    summaries.append("Personal names,${good},${bad},${occurrenceMap.keySet().size()},personalnames.html\n")
    File persReport = new File(verificationDir, "personalnames.html")

    def personsXml = new groovy.xml.StreamingMarkupBuilder().bind {
      //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
      html {
	head {
	  title ("Verification of personal names for ${folio}")
	  link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
	
	}
	body {
	  header(role: "banner") {
	    mkp.yield "HMT-MOM: "
	    nav(role: "navigation") {
	      ul {
		li {
		  a(href:"index.html", "summary")
		}
	      }
	    }
	  }
	  article(role: "main") {
	    h1("Personal names for ${folio}")
	    table {
	      tr {
		th ("Reference")
		th ("Valid?")
		th ("Occurs in")
	      }
	      occurrenceMap.keySet().each { k ->
		tr {
		  td ("${k}")
		  td("${personsList.contains(k)}")
		  td {
		    def psgs = occurrenceMap[k]
		    if (psgs.size() == 1) {
		      mkp.yield "${psgs[0]}"
		    } else {
		      ul {
			psgs.each { p ->
			  li ("${p}")
			}
		      }
		    }
		  }
		}
	      }
	    }
	  }
	}
      }
    }
    persReport.setText(personsXml.toString())
    

  } else {
    println "No tokens file."
  }
}



task placeNames(dependsOn: [tokenize]) {
  description  = "Check that place name identifiers are valid."
}

placeNames.doLast {

  File summaries = new File(buildDir,"summaries.txt")
  File verificationDir = new File(buildDir, "verification")
  File tokens = new File("${buildDir}/tokens/tokens.txt")
  if (tokens.exists()) {
    def placeNames = tokens.readLines().findAll { l -> l ==~ /urn:cite:hmt:place.+/}
    def placeList = []
    File placeFile = new File (placenames)
    placeFile.eachLine {
      def cols = it.split(/,/)
      placeList.add(cols[0])
    }
    println "Check " + placeNames.size() + " place name occurrences  against " + placeList.size() + " authority list entries."


    def placeOccurrenceMap = [:]
    placeNames.each { 
      def cols = it.split(/\t/)
      def pname = cols[0]
      def psg = cols[1]
      if (placeOccurrenceMap[pname]) {
	def psgs = placeOccurrenceMap[pname]
	psgs.add(psg)
	placeOccurrenceMap[pname] =  psgs
      } else {
	placeOccurrenceMap[pname] = [psg]
      }
    }




    Integer goodPlace = 0
    Integer badPlace = 0
    placeOccurrenceMap.keySet().each { k ->
      if (placeList.contains(k)) {
	goodPlace++
      } else {
	badPlace++
      }
    }


    //println "Score: ${goodPlace} / ${badPlace} / total: ${placeOccurrenceMap.keySet().size()}"
    summaries.append("Place names,${goodPlace},${badPlace},${placeOccurrenceMap.keySet().size()},placenames.html\n")
    File placeReport = new File(verificationDir, "placenames.html")

    def placesXml = new groovy.xml.StreamingMarkupBuilder().bind {
      //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
      html {
	head {
	  title ("Verification of place names for ${folio}")
	  link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
	
	}
	body {
	  header(role: "banner") {
	    mkp.yield "HMT-MOM: "
	    nav(role: "navigation") {
	      ul {
	      }
	    }
	  }
	  article (role: "main") {
	    h1("Place names for ${folio}")
	    table {
	      tr {
		th ("Reference")
		th ("Valid?")
		th ("Occurs in")
	      }
	      placeOccurrenceMap.keySet().each { k ->
		tr {
		  td ("${k}")
		  td("${placeList.contains(k)}")
		  td {
		    def psgs = placeOccurrenceMap[k]
		    if (psgs.size() == 1) {
		      mkp.yield "${psgs[0]}"
		    } else {
		      ul {
			psgs.each { p ->
			  li ("${p}")
			}
		      }
		    }
		  }
		}
	      }
	    }
	  }
	}
      }
    }
    placeReport.setText(placesXml.toString())

  } else {
    println "No tokens file."
  }
}

task initReport {
  description = "Initializes a new verification report."
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File summaries = new File(buildDir,"summaries.txt")
  summaries.setText("label,success,failure,total,link\n")
  File verificationDir = new File(buildDir, "verification")
  if (! verificationDir.exists()) {
    verificationDir.mkdir()
  }
}

task copyCss(type: Copy) {
  from "css"
  into "${buildDir}/verification/css"
}

task byzorth (dependsOn: tokenize) {
  description="Check tokens against list of byzantine orthographic variants."
}

byzorth.doLast {
  // write failures to lextokens
  File tokens = new File("${buildDir}/tokens/tokens.txt")
  File lextokens = new File("${buildDir}/tokens/lextokens.txt")
  if (tokens.exists()) {
    tokens.eachLine {
      lextokens.append(it + "\n")
    }
  } else {
    println "No tokens file."
  }
}

task cpCheck(dependsOn: tabulate) {
  description = "Check that code point usage is valid for given document."
}
cpCheck.doLast {
}

task lex1(dependsOn: byzorth) {
  description = "Create word list, in beta code, for morpheus."
}

lex1.doLast {
  File tokens = new File("${buildDir}/tokens/lextokens.txt")
  if (tokens.exists()) {
    def lexItems = tokens.readLines().findAll { l -> l ==~ /urn:cite:perseus:lextoken.+/}
    println "Unique lexical items: " + lexItems.unique().size() + " (${lexItems.size()} total)"
    TransCoder tobeta = new TransCoder()
    tobeta.setConverter("BetaCode")
    tobeta.setParser("Unicode")


    TransCoder frombeta = new TransCoder()
    frombeta.setParser("BetaCode")
    frombeta.setConverter("UnicodeC")

    File summaries = new File(buildDir,"summaries.txt")
    File verificationDir = new File(buildDir, "verification")

    println "Use byz ortho in " + byzortho
    println "Excecute morpheus from " + morpheus


    StringBuffer wordList = new StringBuffer()
    lexItems.each { lex ->
      def cols = lex.split(/\t/)
      def token = cols[0].replace(/urn:cite:perseus:lextoken./,"")
      println "${token} -> ${tobeta.getString(token)}"
      wordList.append(tobeta.getString(token) + "\n")
    }

    if (wordList.toString().readLines().size() > 0) {
      File morphin = new File(buildDir, "wordlist.txt")
      morphin.setText(wordList.toString())
      println "Wrote " + morphin.readLines().size() + " tokens to file."
    } else {
      println "No tokens in tokens file."
    }


  } else {
    println "No tokens file."
  }

}


task lex2(dependsOn: lex1) {
  description="Invoke morpheus on wordlist"
}

lex2.doLast {
  File morphin  = new File (buildDir, "wordlist.txt")

  Integer success = 0
  Integer fail = 0
  Integer count = 0
  morphin.eachLine { l ->
    if (l.size() > 0) {
      count++
      def command = "${morpheus} ${l}"
      print "${count}: Analyzing ${l}..."
      def proc = command.execute()
      proc.waitFor()
      def reply = proc.in.text.readLines()


      /*
      def lexOccurrenceMap = [:]
    placeNames.each { 
      def cols = it.split(/\t/)
      def pname = cols[0]
      def psg = cols[1]
      if (placeOccurrenceMap[pname]) {
	def psgs = placeOccurrenceMap[pname]
	psgs.add(psg)
	placeOccurrenceMap[pname] =  psgs
      } else {
	placeOccurrenceMap[pname] = [psg]
      }
    }
      */
      if (reply[1] ==~ /.*unknown.+/) {
	fail++
	println " fail."
      } else {
	success++
	println " success."
      }
    }
  }
  File summaries = new File(buildDir,"summaries.txt")
  summaries.append("Lexical tokens,${success},${fail},${success + fail},lextokens.html\n")  

  File verificationDir = new File(buildDir, "verification")
  File lexReport = new File(verificationDir, "lextokens.html")

    def lexXml = new groovy.xml.StreamingMarkupBuilder().bind {
      //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
      html {
	head {
	  title ("Verification of lexical tokens for ${folio}")
	  link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
	
	}
	body {
	  header(role: "banner") {
	    mkp.yield "HMT-MOM: "
	    nav(role: "navigation") {
	      ul {
		li {
		  a(href:"index.html", "summary")
		}
	      }
	    }
	  }
	  article (role: "main") {
	    h1("Lexical tokens for ${folio}")
	    table {
	      tr {
		th ("Reference")
		th ("Valid?")
		th ("Occurs in")
	      }
	      /*
	      placeOccurrenceMap.keySet().each { k ->
		tr {
		  td ("${k}")
		  td("${placeList.contains(k)}")
		  td {
		    def psgs = placeOccurrenceMap[k]
		    if (psgs.size() == 1) {
		      mkp.yield "${psgs[0]}"
		    } else {
		      ul {
			psgs.each { p ->
			  li ("${p}")
			}
		      }
		    }
		  }
		}
		}*/
	    }
	  }
	}
      }
    }
    lexReport.setText(lexXml.toString())
 
}

task concordance(dependsOn: tokenize) {
  description = "Compiles alphabetized concordance of lexical tokens on this surface"
}
concordance.doLast {
  println "Concordance: not yet implemented."
}
task verify(dependsOn: [initReport, persNames, placeNames, lex2, copyCss, concordance, cpCheck]) {
    description = "Runs full verification suite on requested URN(s)"
}

verify.doFirst {
  System.out.println "Verifying folio ${folio}\n"
}


verify.doLast {
  
  DseManager dse = new DseManager()
  dse.debug = 5
  
  File summaries = new File(buildDir, "summaries.txt")

  def reportXml = new groovy.xml.StreamingMarkupBuilder().bind {
    //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
    html {
      head {
	title ("Summary of verification for ${folio}")
	link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
      }
      body {
	header(role: "banner") {
	  mkp.yield "HMT-MOM: "
	  nav(role: "navigation") {
	    ul {
	      li {
		a(href:"index.html", "summary")
	      }
	    }
	  }
	}
	article (role: "main") {
	  h1 ("Page ${folio} â€” summary of verification")
	  p("MOM version: ${version}")
	  p("DSE reports are not yet integrated in this web page:  see separate feedback in terminal.")
	  p {
	    mkp.yield "Also see a "
	    a(href: "../visualinventory/", "visual inventory")
	    mkp.yield " of indexed text passages. "
	    mkp.yield "(Open with Safari or Firefox.)"
	  }


	  table {
	    tr {
	      th("Report")
	      th("Success/Failure/Total")
	      th("Details")
	    }
	    Integer reportCount = 0
	    summaries.eachLine { ln ->
	      reportCount++
		if (reportCount > 1) {
		  def cols = ln.split(/,/)
		  Integer success = cols[1].toInteger()
		  Integer fail = cols[2].toInteger()
		  Integer total = cols[3].toInteger()
		  tr {
		    td {
		      if  (success == total) {
			img(src: "css/check.png")
			mkp.yield(cols[0])
		      } else {
			img(src: "css/delete.png")
			mkp.yield(cols[0])
		      }

		    }
		    td("${cols[1]}/${cols[2]}/${cols[3]}")
		    td {
		      a(href : "${cols[4]}", "details")
		    }
		  }
		}
	    }
	  }
	}
      }
    }
  }

  File summaryReport = new File("${buildDir}/verification/index.html")
  summaryReport.setText(reportXml.toString())

  System.out.println "Completed verification of ${folio}."
  System.out.println "See a summary of results in ${buildDir}/verification/index.html."

}