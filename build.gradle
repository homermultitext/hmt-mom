/* HMT project Mandatory Ongoing Maintenance. 
   Summer 2014 version.
*/
buildscript {
    repositories {
        mavenCentral()
	maven {
	  url "http://beta.hpcc.uh.edu/nexus/content/groups/public"
	}
    }
    dependencies {
      classpath group: 'org.homermultitext', name : 'citemgr' , version: '0.5.4'
      classpath group: 'org.homermultitext', name : 'hmt-utils' , version: '0.2.8'

      classpath group: 'edu.harvard.chs', name : 'cite' , version: '0.14.2'
      classpath group: 'edu.holycross.shot', name: 'hocuspocus', version : '0.7.27'

      classpath group: 'edu.harvard.chs', name : 'greekutils' , version: '0.8.5'

      classpath group : 'edu.unc.epidoc', name: 'transcoder', version : '1.2-SNAPSHOT'

      classpath group: 'net.sf.opencsv', name: 'opencsv', version: '2.3'


    }
}

import org.homermultitext.utils.HmtTokenizer

import edu.harvard.chs.cite.CiteUrn
import edu.harvard.chs.cite.CtsUrn

import edu.holycross.shot.hocuspocus.Corpus

import org.homermultitext.citemanager.DseManager

import edu.harvard.chs.f1k.GreekNode

import edu.unc.epidoc.transcoder.TransCoder

import au.com.bytecode.opencsv.CSVReader
import groovy.xml.StreamingMarkupBuilder

import org.apache.tools.ant.filters.*

apply plugin: "base"
apply plugin:  "groovy"
apply plugin:  "maven"


apply from: "versions.gradle"


if (hasProperty('conf')) {
    System.err.println "Using configuration data from ${conf}"
    File confFile = new File(conf)
    if (! confFile.exists()) {
        throw new Exception("No configuration file ${conf} found.")
    }
    apply from: conf

} else {
    File confFile = new File("conf.gradle")
    if (! confFile.exists()) {
        throw new Exception("No configuration file ${conf} found.")
    }
    System.err.println "Using conf.gradle for configuration"
    apply from: "conf.gradle"
    
}



if (hasProperty('repoconf')) {
    System.err.println "Using repository locations data from ${repoconf}"
    File confFile = new File(repoconf)
    if (! confFile.exists()) {
        throw new Exception("No file ${repoconf} found.")
    }
    apply from: repoconf

} else {
    File confFile = new File("repos.gradle")
    if (! confFile.exists()) {
        throw new Exception("No configuration file ${confFile} found.")
    }
    System.err.println "Using repos.gradle for finding repositories."
    apply from: "repos.gradle"
}



group = "org.homermultitext"
version = '1.0.test1'

repositories {
    mavenCentral()
    maven {
        url "http://beta.hpcc.uh.edu/nexus/content/groups/public"
    }
}

dependencies {
  compile group: 'org.codehaus.groovy', name: 'groovy-all', version: groovyVersion
  compile group: 'org.homermultitext', name : 'citemgr' , version: '0.4.5'

  compile group: 'edu.harvard.chs', name : 'cite' , version: citeversion

    testCompile group: 'junit', name: 'junit', version: '4.8.2'

}


task palView() {
  description = "Creates HTML page displaying paleographic inventory data."
}

palView.doLast {
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File outputDir = new File(buildDir, "paleography")
  if (! outputDir.exists()) {
    outputDir.mkdir()
  }
  File outputFile = new File(outputDir, "viewer.html")


  String urnBase = "http://beta.hpcc.uh.edu/tomcat/hmt-digital/images?request=GetBinaryImage&w=9000&urn="

  File palFile = new File(paleo)
  CSVReader reader = new CSVReader(new FileReader(palFile))

  StreamingMarkupBuilder xml = new StreamingMarkupBuilder()
  xml.encoding = "UTF-8"

  def doc = xml.bind {
    mkp.xmlDeclaration()
    html {
      head () {
      }
      body{

	table {
	  tr {
	    th ("Reading")
	    th ("Image")
	  }
	  reader.readAll().each { ln ->
	    if (ln.size() >= 3) {
	      tr {
		CtsUrn urn
		String urnVal
		try {
		  urn = new CtsUrn(ln[1])
		  urnVal = urn.getSubref1()
		  td (urnVal)
		  td {
		    img(src : "${urnBase}${ln[2]}")
		  }

		} catch (Exception e) {
		  System.err.println "Bad CTS URN: " + ln[1]
		}
	      }
	    }
	  }
	}
      }
    }
  }
  outputFile.setText(doc.toString(), "UTF-8")
  System.err.println "Paleography observations in ${outputDir}/viewer.html"
} /*end palView task */


task setUpVisualInventory(type: Copy) {
  description="Copy template files for visual inventory to build area."
  from "visualinventory"
  into "${buildDir}/visualinventory"
}


task indexScholia() {
  description = "Reads inventory of scholia, and creates separate indices for surfaces and images"
}


indexScholia.doLast {
  if (!buildDir.exists()) {
    buildDir.mkdir()
  }
  File scholiaToTbs = new File(buildDir, "scholiaToTbs.csv")
  File scholiaToImg = new File(buildDir,"scholiaToImage.csv")

  scholiaInventories.split(/,/).each { inv ->
    if (inv) {
      File invFile = new File(inv)
      if (invFile) {
	CSVReader reader = new CSVReader(new FileReader(invFile))
	reader.readAll().each { ln ->
	  if (ln.size() > 3) {
	    scholiaToTbs.append(ln[0] + ',"' + ln[3] + '"\n')
	    scholiaToImg.append(ln[0] + ',"' + ln[2] + '"\n')
	  }
	}
      }
    }
  }
}


task dse(dependsOn : [setUpVisualInventory, indexScholia]) {
  description = "Does citemgr's DSE validation,  and creates an XML visual inventory for the specified folio."
}

dse.doLast {
  DseManager dse = new DseManager()

  folioToImage.split(/,/).each { idx ->
    if (dse.tbsImageIndexFiles) {
      dse.tbsImageIndexFiles.add(new File(idx))
    } else {
      dse.tbsImageIndexFiles = [new File(idx)]
    }
  }

  textToImage.split(/,/).each { idx ->
    if (dse.textImageIndexFiles) {
      dse.textImageIndexFiles.add(new File(idx))
    } else {
      dse.textImageIndexFiles = [new File(idx)]
    }
  }

  textToFolio.split(/,/).each { idx ->
    if (dse.textTbsIndexFiles) {
      dse.textTbsIndexFiles.add(new File(idx))
    } else {
      dse.textTbsIndexFiles = [new File(idx)]
    }
  }
  dse.textTbsIndexFiles.add(new File (buildDir, "scholiaToTbs.csv"))


  println "Created DSE Manager"

  CiteUrn urn
  try {
    urn  = new CiteUrn(folio)
  } catch (Exception e) {
    System.err.println "Unable to make urn for folio ${folio}"
    throw e
  }


  /**
  if (urn.isRange() ) {
    println "Do a range!"

    throw new Exception("Not ready for ranges.")
    }*/


  
  CiteUrn  img = dse.imageForTbs(folio)

  System.err.println "Default image: " + img

  if (!img) {
    System.err.println "No default image for " + folio
    throw new Exception("For folio ${folio}: no default image.")
  }
  def iMaps
  //dse.debug = 10
  try {
    iMaps = dse.imageMapsByText(img)
  } catch (Exception e)  {
    System.err.println "Unable to get image maps for ${img}."
  }


  
  String xml =  dse.getVisualInventoryXml(urn)

  //String fName = "${buildDir}/visualinventory/inventory.xml"
  String fName = "${buildDir}/visualinventory/${urn.getCollection()}_${urn.getObjectId()}.xml"
  File visinv = new File(fName)
  visinv.setText(xml,"UTF-8")

  dse.verifyTbs(folio)

}


task tabulate(dependsOn: dse) {
  description = "Writes tabulated form of all inventoried texts in ${buildDir}/tabulated."
}


tabulate.doLast {
  File tiFile = new File(textInventory)
  File archiveDir = new File(textArchive)

  File tabDir = new File(buildDir,"tabulated")
  if (! buildDir.exists()) { 
    buildDir.mkdir()
  }
  if (! tabDir.exists()) {
    tabDir.mkdir()
  }

  Corpus c = new Corpus(tiFile, archiveDir)
  c.debug = 5
  c.tabulateRepository(tabDir)
}

task textsForSurface(dependsOn: tabulate) {
  description="Selects tabulated text data for requested text-bearing surface."
}

textsForSurface.doLast {
  // input and output files:
  File tabsDir = new File(buildDir, "tabulated")

  // Get a hocuspocus corpus for text repository:
  File archiveDir = new File(textArchive)
  File tiFile = new File(textInventory)
  Corpus corpus = new Corpus(tiFile, archiveDir)

  // configure a DseManager:
  DseManager dse = new DseManager()

  folioToImage.split(/,/).each { idx ->
    if (dse.tbsImageIndexFiles) {
      dse.tbsImageIndexFiles.add(new File(idx))
    } else {
      dse.tbsImageIndexFiles = [new File(idx)]
    }
  }

  textToImage.split(/,/).each { idx ->
    if (dse.textImageIndexFiles) {
      dse.textImageIndexFiles.add(new File(idx))
    } else {
      dse.textImageIndexFiles = [new File(idx)]
    }
  }
  dse.textImageIndexFiles.add(new File(buildDir, "scholiaToImage.csv"))

  textToFolio.split(/,/).each { idx ->
    if (dse.textTbsIndexFiles) {
      dse.textTbsIndexFiles.add(new File(idx))
    } else {
      dse.textTbsIndexFiles = [new File(idx)]
    }
  }
  dse.textTbsIndexFiles.add(new File (buildDir, "scholiaToTbs.csv"))

  //dse.debug = 5

  // get relevant tabular data, and tokenize it:
  ArrayList tabData = dse.tabDataForSurface(folio, corpus, tabsDir)
  

  File outputDir = new File(buildDir, "surfaceTabs")
  if (! outputDir.exists()) {
    outputDir.mkdir()
  }

  File tabDataFile = new File(outputDir, "tab.txt")
  tabData.each {
    tabDataFile.append(it + "\n", "UTF-8")
  }
  
  if (hasProperty('debug')) {
    println "debug is on."
  }
    println "textsForSurface settings:"
    println "\tcorpus built from " + textArchive + " with inventory " + textInventory
    println "\ttabsDir was " + tabsDir 
    //}

}


  //task tokenize {
task tokenize(dependsOn: textsForSurface) {
  description = "Creates HMT classified tokenization of texts for given page"
  
}

tokenize.doLast {
  // input and output files:
  File surfTabsDir = new File(buildDir, "surfaceTabs")
  File outputDir = new File(buildDir, "tokens")
  if (! outputDir.exists()) {
    outputDir.mkdir()
  }
  File tokensFile = new File(outputDir, "tokens.txt")

  String fldSeparator = "#"
  HmtTokenizer hmtTokens = new HmtTokenizer(surfTabsDir, tokensFile, fldSeparator)
  hmtTokens.tokenizeTabs()
}


task persNames(dependsOn: [tokenize]) {
  description  = "Check that personal name identifiers are valid."
}
persNames.doLast {
  File summaries = new File(buildDir,"summaries.txt")
  File verificationDir = new File(buildDir, "verification")

  File tokens = new File("${buildDir}/tokens/tokens.txt")
  if (tokens.exists()) {
    def persNames = tokens.readLines().findAll { l -> l ==~ /urn:cite:hmt:pers.+/}
    def occurrenceMap = [:]
    persNames.each { 
      def cols = it.split(/\t/)
      def pname = cols[0]
      def psg = cols[1]
      if (occurrenceMap[pname]) {
	def psgs = occurrenceMap[pname]
	psgs.add(psg)
	occurrenceMap[pname] =  psgs
      } else {
	occurrenceMap[pname] = [psg]
      }
    }

    def personsList = []
    File personsFile = new File (persnames)
    personsFile.eachLine {
      def cols = it.split(/,/)
      personsList.add(cols[0])
    }
    println "Check " + persNames.size() + " personal name occurrences  against " + personsList.size() + " authority list entries."
    
    Integer good = 0
    Integer bad = 0
    def scoreMap = [:]
    occurrenceMap.keySet().each { k ->
      if (personsList.contains(k)) {
	good++
	  
      } else {
	bad++
      }
    }
    summaries.append("Personal names,${good},${bad},${occurrenceMap.keySet().size()},personalnames.html\n")
    File persReport = new File(verificationDir, "personalnames.html")

    def personsXml = new groovy.xml.StreamingMarkupBuilder().bind {
      //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
      html {
	head {
	  title ("Verification of personal names for ${folio}")
	  link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
	
	}
	body {
	  header(role: "banner") {
	    mkp.yield "HMT-MOM: "
	    nav(role: "navigation") {
	      ul {
		li {
		  a(href:"index.html", "summary")
		}
	      }
	    }
	  }
	  article(role: "main") {
	    h1("Personal names for ${folio}")
	    table {
	      tr {
		th ("Reference")
		th ("Valid?")
		th ("Occurs in")
	      }
	      occurrenceMap.keySet().each { k ->
		tr {
		  td ("${k}")
		  td {
		    if (personsList.contains(k)) {
		      img(src: "css/check.png")
		    } else {
		      img(src: "css/delete.png")
		    }
		  }
		  td {
		    def psgs = occurrenceMap[k]
		    if (psgs.size() == 1) {
		      mkp.yield "${psgs[0]}"
		    } else {
		      ul {
			psgs.each { p ->
			  li ("${p}")
			}
		      }
		    }
		  }
		}
	      }
	    }
	  }
	}
      }
    }
    persReport.setText(personsXml.toString())
    

  } else {
    println "No tokens file."
  }
}


task ethnics(dependsOn: [tokenize]) {
  description  = "Check that ethnic adjective identifiers are valid."
}
ethnics.doLast {
  File summaries = new File(buildDir,"summaries.txt")
  File verificationDir = new File(buildDir, "verification")

  File tokens = new File("${buildDir}/tokens/tokens.txt")
  if (tokens.exists()) {
    def ethnicNames = tokens.readLines().findAll { l -> l ==~ /urn:cite:hmt:peoples.+/}
    def occurrenceMap = [:]
    ethnicNames.each { 
      def cols = it.split(/\t/)
      def ename = cols[0]
      def psg = cols[1]
      if (occurrenceMap[ename]) {
	def psgs = occurrenceMap[ename]
	psgs.add(psg)
	occurrenceMap[ename] =  psgs
      } else {
	occurrenceMap[ename] = [psg]
      }
    }
    println "Using placenames list in " + placenames
    def ethnicsList = []
    File ethnicsFile = new File(placenames)
    ethnicsFile.eachLine {
      def cols = it.split(/,/)
      ethnicsList.add(cols[0])
    }
    println "Check " + ethnicNames.size() + " ethnic name occurrences  against " + ethnicsList.size() + " authority list entries."



    Integer good = 0
    Integer bad = 0
    def scoreMap = [:]

    occurrenceMap.keySet().each { k ->
      String place = k.replace("hmt:peoples","hmt:place")
      if (ethnicsList.contains(place)) {
	good++

      } else {
	bad++
      }
    }
    println "${good}/${bad}/${occurrenceMap.keySet().size()}"


    summaries.append("Ethnic adjectives,${good},${bad},${occurrenceMap.keySet().size()},ethnics.html\n")
    File ethnicReport = new File(verificationDir, "ethnics.html")

    def ethnicsXml = new groovy.xml.StreamingMarkupBuilder().bind {
      //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
      html {
	head {
	  title ("Verification of ethnic adjectives for ${folio}")
	  link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
	
	}
	body {
	  header(role: "banner") {
	    mkp.yield "HMT-MOM: "
	    nav(role: "navigation") {
	      ul {
		li {
		  a(href:"index.html", "summary")
		}
	      }
	    }
	  }
	  article(role: "main") {
	    h1("Ethnic adjectives for ${folio}")
	    table {
	      tr {
		th ("Reference")
		th ("Valid?")
		th ("Occurs in")
	      }
	      occurrenceMap.keySet().each { k ->
		String place = k.replace("hmt:peoples","hmt:place")
		tr {
		  td ("${k}")
		  td {
		    if (ethnicsList.contains(place)) {
		      img(src: "css/check.png")
		    } else {
		      img(src: "css/delete.png")
		    }
		  }
		  td {
		    def psgs = occurrenceMap[k]
		    if (psgs.size() == 1) {
		      mkp.yield "${psgs[0]}"
		    } else {
		      ul {
			psgs.each { p ->
			  li ("${p}")
			}
		      }
		    }
		  }
		}
	      }
	    }
	  }
	}
      }
    }
    ethnicReport.setText(ethnicsXml.toString())


  } else {
    println "No tokens file."
  }
}




task placeNames(dependsOn: [tokenize]) {
  description  = "Check that place name identifiers are valid."
}

placeNames.doLast {

  File summaries = new File(buildDir,"summaries.txt")
  File verificationDir = new File(buildDir, "verification")
  File tokens = new File("${buildDir}/tokens/tokens.txt")
  if (tokens.exists()) {
    def placeNames = tokens.readLines().findAll { l -> l ==~ /urn:cite:hmt:place.+/}
    def placeList = []
    File placeFile = new File (placenames)
    placeFile.eachLine {
      def cols = it.split(/,/)
      placeList.add(cols[0])
    }
    println "Check " + placeNames.size() + " place name occurrences  against " + placeList.size() + " authority list entries."


    def placeOccurrenceMap = [:]
    placeNames.each { 
      def cols = it.split(/\t/)
      def pname = cols[0]
      def psg = cols[1]
      if (placeOccurrenceMap[pname]) {
	def psgs = placeOccurrenceMap[pname]
	psgs.add(psg)
	placeOccurrenceMap[pname] =  psgs
      } else {
	placeOccurrenceMap[pname] = [psg]
      }
    }




    Integer goodPlace = 0
    Integer badPlace = 0
    placeOccurrenceMap.keySet().each { k ->
      if (placeList.contains(k)) {
	goodPlace++
      } else {
	badPlace++
      }
    }

    summaries.append("Place names,${goodPlace},${badPlace},${placeOccurrenceMap.keySet().size()},placenames.html\n")
    File placeReport = new File(verificationDir, "placenames.html")

    def placesXml = new groovy.xml.StreamingMarkupBuilder().bind {
      //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
      html {
	head {
	  title ("Verification of place names for ${folio}")
	  link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
	
	}
	body {
	  header(role: "banner") {
	    mkp.yield "HMT-MOM: "
	    nav(role: "navigation") {
	      ul {
		li {
		  a(href:"index.html", "summary")
		}
	      }
	    }
	  }
	  article (role: "main") {
	    h1("Place names for ${folio}")
	    table {
	      tr {
		th ("Reference")
		th ("Valid?")
		th ("Occurs in")
	      }
	      placeOccurrenceMap.keySet().each { k ->
		tr {
		  td ("${k}")
		  td {
		    if (placeList.contains(k)) {
		      img(src: "css/check.png")
		    } else {
		      img(src: "css/delete.png")
		    }
		  }
		  td {
		    def psgs = placeOccurrenceMap[k]
		    if (psgs.size() == 1) {
		      mkp.yield "${psgs[0]}"
		    } else {
		      ul {
			psgs.each { p ->
			  li ("${p}")
			}
		      }
		    }
		  }
		}
	      }
	    }
	  }
	}
      }
    }
    placeReport.setText(placesXml.toString())

  } else {
    println "No tokens file."
  }
}

task initReport {
  description = "Initializes a new verification report."
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File summaries = new File(buildDir,"summaries.txt")
  summaries.setText("label,success,failure,total,link\n")
  File verificationDir = new File(buildDir, "verification")
  if (! verificationDir.exists()) {
    verificationDir.mkdir()
  }
}

task copyCss(type: Copy) {
  from "css"
  into "${buildDir}/verification/css"
}


//task lex(dependsOn: tokenize) {
task lex {
  description = "Analyzes lexical tokens."
}

lex.doLast {
  // All tokens, as created by tokenize task:
  File tokens = new File("${buildDir}/tokens/tokens.txt")

  if (tokens.exists()) {
    // 2 data structures:
    // 1. Map of unique tokens to passages:
    def passageMap = [:]

    // 2. record of analysis:  analyze each token as one of 
    // a) byz (appears in byz ortho list), 
    // b) success (morpheus parses), 
    // c) fail (neither of the preceding)
    def statusMap = [:]

    // Lexical tokens for morpheus to analyze:
    File lexTokensFile = new File("${buildDir}/tokens/lextokens.txt")


    def lexItems = tokens.readLines().findAll { l -> l ==~ /urn:cite:perseus:lextoken.+/}
    println "Unique lexical items: " + lexItems.unique().size() + " (${lexItems.size()} total)"

    lexItems.each { 
      def cols = it.split(/\t/)
      def lex = cols[0]
      def psg = cols[1]
      if (passageMap[lex]) {
	def psgs = passageMap[lex]
	psgs.add(psg)
	passageMap[lex] =  psgs
      } else {
	passageMap[lex] = [psg]
      }
    }

    TransCoder tobeta = new TransCoder()
    tobeta.setConverter("BetaCode")
    tobeta.setParser("Unicode")

    File summaries = new File(buildDir,"summaries.txt")
    File verificationDir = new File(buildDir, "verification")

    println "Use byz ortho in " + byzortho
    File byzorth = new File( byzortho)

    def orthoAuthorityList = []
    Integer count = 0
    byzorth.eachLine { l ->
      if (count > 0) {
	def cols = l.split(/,/)
	if (l.size() == 0) {
	  // omit
	} else {
	  if (cols[3] != "rejected") {
	    orthoAuthorityList.add( tobeta.getString(cols[1]) )
	  }
	}
      }
      count = count + 1
    }

    Integer success = 0
    Integer fail = 0
    Integer lexCount = 0

    lexItems.each { lex ->
      lexCount = lexCount + 1
      def cols = lex.split(/\t/)
      String tokenUrn = cols[0]
      String token = tokenUrn.replace(/urn:cite:perseus:lextoken./,"")
      String betaToken = tobeta.getString(token.toLowerCase())
      if ((token.size() < 1) || (token == "⁑")){
	println "${lexCount}: omit punctuation ${token}"
      } else if (orthoAuthorityList.contains(betaToken)) {

	println "${lexCount}: Byzantine orthography ok: " + token
	statusMap[tokenUrn] = "byz"

      } else {

	def command = "${morpheus} ${betaToken}"
	print "${lexCount}: Analyzing ${token}..."
	def proc = command.execute()
	proc.waitFor()
	def reply = proc.in.text.readLines()

	if (reply[1] ==~ /.*unknown.+/) {
	  statusMap[tokenUrn]  = "fail"
	  fail = fail + 1
	  println " fail."
	} else {
	  statusMap[tokenUrn]  = "success"
	  success = success + 1
	  println " success."
	}
      }
    }


    summaries.append("Lexical tokens,${success},${fail},${success + fail},lextokens.html\n")  

    File lexReport = new File(verificationDir, "lextokens.html")
    def lexXml = new groovy.xml.StreamingMarkupBuilder().bind {
      //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
      html {
	head {
	  title ("Verification of lexical tokens for ${folio}")
	  link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
	
	}
	body {
	  header(role: "banner") {
	    mkp.yield "HMT-MOM: "
	    nav(role: "navigation") {
	      ul {
		li {
		  a(href:"index.html", "summary")
		}
	      }
	    }
	  }
	  article (role: "main") {
	    h1("Lexical tokens for ${folio}")
	    table {
	      tr {
		th ("Reference")
		th ("Valid?")
		th ("Occurs in")
	      }

	      // cycle each token in status map
	      // report its passages from occurrence map
	      statusMap.keySet().each { k ->
		tr {
		  td(k)
		  td {
		    if (statusMap[k] == "byz") {
		      img(src: "css/check.png")
		      
		    } else if (statusMap[k] == "success") {
		      img(src: "css/check.png")
		    } else {
		      img(src: "css/delete.png")
		    }
		  }
		    
		  td {
		    def psgs =  passageMap[k]
		    if (psgs.size() > 1) {
		      ul {
			psgs.each {
			  li(it)
			}
		      }
		    } else {
		      mkp.yield (psgs[0])
		    }
		  }
		}
	      }
	    }
	  }
	}
      }
    }
    lexReport.setText(lexXml.toString())

  } else {
    println "No tokens file."
  }

}



task cpCheck(dependsOn: tabulate) {
  description = "Checks that unicode code point usage is valid for given document."
}
cpCheck.doLast {
  //println "Validation of unicode code point usage not yet implemented."
}


task verify(dependsOn: [initReport, persNames, placeNames, lex, ethnics, copyCss, cpCheck]) {
    description = "Runs full verification suite on requested URN(s)"
}
verify.doFirst {
  System.out.println "Preparing report on folio ${folio}\n"
}
verify.doLast {
  DseManager dse = new DseManager()
  dse.debug = 0
  
  File summaries = new File(buildDir, "summaries.txt")

  def reportXml = new groovy.xml.StreamingMarkupBuilder().bind {
    //mkp.pi("xml-stylesheet": "type='text/xsl' href='xslt/image.xsl'" )
    html {
      head {
	title ("Summary of verification for ${folio}")
	link(type: "text/css", rel: "stylesheet", href: "css/hmt-core.css", title: "HMT CSS")
      }
      body {
	header(role: "banner") {
	  mkp.yield "HMT-MOM: "
	  nav(role: "navigation") {
	    ul {
	      li {
		a(href:"index.html", "summary")
	      }
	    }
	  }
	}
	article (role: "main") {
	  h1 ("Page ${folio} — summary of verification")
	  p {
	    strong("MOM version: ${version}")
	  }
	  p("DSE reports are not yet integrated in this web page:  see separate feedback in terminal.")
	  p {
	    mkp.yield "Also see a "
	    a(href: "../visualinventory/", "visual inventory")
	    mkp.yield " of indexed text passages. "
	    mkp.yield "(Open with Safari or Firefox.)"
	  }


	  table {
	    tr {
	      th("Report")
	      th("Success/Failure/Total")
	      th("Details")
	    }
	    Integer reportCount = 0
	    summaries.eachLine { ln ->
	      reportCount++
		if (reportCount > 1) {
		  def cols = ln.split(/,/)
		  Integer success = cols[1].toInteger()
		  Integer fail = cols[2].toInteger()
		  Integer total = cols[3].toInteger()
		  tr {
		    td {
		      if  (success == total) {
			img(src: "css/check.png")
			mkp.yield(cols[0])
		      } else {
			img(src: "css/delete.png")
			mkp.yield(cols[0])
		      }

		    }
		    td("${cols[1]}/${cols[2]}/${cols[3]}")
		    td {
		      a(href : "${cols[4]}", "details")
		    }
		  }
		}
	    }
	  }
	}
      }
    }
  }

  File summaryReport = new File("${buildDir}/verification/index.html")
  summaryReport.setText(reportXml.toString())

  System.out.println "Completed verification of ${folio}."
  System.out.println "See a summary of results in ${buildDir}/verification/index.html."

}


task dserange(dependsOn : [setUpVisualInventory, indexScholia]) {
}
dserange.doLast {
  DseManager dse = new DseManager()
  def scorecard = []
  def reptDetails = [:]
  
  Integer totalGood = 0
  folioToImage.split(/,/).each { idx ->
    if (dse.tbsImageIndexFiles) {
      dse.tbsImageIndexFiles.add(new File(idx))
    } else {
      dse.tbsImageIndexFiles = [new File(idx)]
    }
  }

  textToImage.split(/,/).each { idx ->
    if (dse.textImageIndexFiles) {
      dse.textImageIndexFiles.add(new File(idx))
    } else {
      dse.textImageIndexFiles = [new File(idx)]
    }
  }

  textToFolio.split(/,/).each { idx ->
    if (dse.textTbsIndexFiles) {
      dse.textTbsIndexFiles.add(new File(idx))
    } else {
      dse.textTbsIndexFiles = [new File(idx)]
    }
  }
  dse.textTbsIndexFiles.add(new File (buildDir, "scholiaToTbs.csv"))


  println "Created DSE Manager"

  CiteUrn urn
  try {
    urn  = new CiteUrn(folio)
  } catch (Exception e) {
    System.err.println "Unable to make urn for ${folio}"
    throw e
  }
  def range = urn.getObjectId().split(/-/)
  String startUrn = "urn:cite:${urn.getNs()}:${urn.getCollection()}.${range[0]}"
  String endUrn = "urn:cite:${urn.getNs()}:${urn.getCollection()}.${range[1]}"

  File venAseq = new File(repo + "/cite/collections/codexModels/venetusA.csv")
  println "Running DSE from folio " +startUrn + " to " + endUrn
  boolean inSeq = false

  Integer lineCount = 0
  venAseq.eachLine { l ->
    if (lineCount > 0) {
      def cols = l.split(/,/)
      String currUrnStr = cols[1]
      CiteUrn currUrn
      try {
	currUrn = new CiteUrn(currUrnStr)
      } catch (Exception e) {
	throw new Exception("Could not make URN from ${currUrnStr}")
      }

      if (cols[1] == startUrn) {
	inSeq = true
      }

      if (inSeq)  {
	def rept = dse.dseReport(currUrn)
	reptDetails[currUrn.toString()] = rept

	String xml =  dse.getVisualInventoryXml(currUrn)
	String fName = "${buildDir}/visualinventory/${urn.getCollection()}_${currUrn.getObjectId()}.xml"
	File visinv = new File(fName)
	visinv.setText(xml,"UTF-8")
	boolean passfail = dse.verifyTbs(currUrn)
	if (passfail) { totalGood++ }
	def score = [currUrn,passfail]
	scorecard.add(score)
      }

      if (cols[1] == endUrn) {
	inSeq = false
      }
    }
    lineCount++;
  }

  def xml = new groovy.xml.StreamingMarkupBuilder().bind {
    
    html {
	head {
	  title("DSE validation, folios ${folio}")
	}
	body {
	  h1("DSE validation, folios ${folio}")
	  h2("Summary")
	  p {
	    mkp.yield "Totals:  "
	    strong "${scorecard.size()}"
	    mkp.yield " pages examined, "
	    strong "${totalGood}"
	    mkp.yield " pages pass DSE validation."
	  }
	  h2("Page-by-page record")
	  p {
	    mkp.yield "Visual inventories for individual pages are in the "
	    code("visualinventory")
	    mkp.yield "subdirectory."
	  }

	  
	  table {

	    tr {
	      th("Page")
	      th("Summary")
	      th("See visual inventory")
	      th("Default image")
	      th("Same texts indexed to image and surface")
	      th("Notes")
	      
	    }
	    scorecard.each { pair ->
	      CiteUrn pg = pair[0]
	      String defaultImg = "none found"
	      
	      String bgcolor = "#ffb0b0"
	      String summary = "Failed one or more tests."
	      if (pair[1]) {
		bgcolor = "#afa"
		summary = "Passed all tests."
	      }
	      tr {
		td("${pg}")
		td(style: "padding: 0.2em; background-color: ${bgcolor};",summary)
		td {

		  a (href: "visualinventory/${pg.getCollection()}_${pg.getObjectId()}.xml", "inventory for ${pg.getObjectId()}")
		}

		def details = reptDetails[pg.toString()]
		def imgRept = details[0]
		def mappingRept = details[1]

		bgcolor = "#ffb0b0"

		if (imgRept[0]) {
		  bgcolor = "#afa"
		  defaultImg = imgRept[1]
		}
		td(style: "padding: 0.2em; background-color: ${bgcolor};",defaultImg)

		bgcolor = "#ffb0b0"
		if (mappingRept[0]) {
		  bgcolor = "#afa"
		}
		td(style: "padding: 0.2em; background-color: ${bgcolor};",mappingRept[1])

		
		def txtCheck = dse.textNodesForSurface(pg)
		if (txtCheck.size() == 0) {
		  td(style: "padding: 0.2em; background-color: #ffffcc;", "Caution: no text units found for this page.")

		  
		} else {
		  // check for no Iliad text
		  String iliad = "urn:cts:greekLit:tlg0012.tlg001.msA"
		  def iMapKeys = dse.imageMapsByText(defaultImg).keySet()
		  
		  if (! iMapKeys.contains(iliad)) {
		    System.err.println("TEXT KEYS: " + iMapKeys )
		    td(style: "padding: 0.2em; background-color: #ffffcc;") {
		      strong("Caution")
		      mkp.yield ": no "
		      em("Iliad")
		      mkp.yield (" text found for this page.")
		    }
		    
		  } else {
		    td("")
		  }
		}
	      }
	    }
	  }
	}
    }
  }

  
  File totals = new File("${buildDir}/${urn.getObjectId()}.html")
  totals.setText(xml.toString(), "UTF-8")

  println ""
  println "Results of DSE validation are in ${buildDir}/${urn.getObjectId()}.html"
}
